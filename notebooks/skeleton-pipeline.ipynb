{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "os.chdir('/Users/seba/local-projects/pedestrians')\n",
    "\n",
    "\n",
    "from src import data_utils, frame_extract\n",
    "from data.jaad.jaad_data import JAAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database saved to data/processed/jaad_database.pkl\n"
     ]
    }
   ],
   "source": [
    "jaad_dir = os.path.join('data/jaad')\n",
    "\n",
    "\n",
    "jaad = JAAD(jaad_dir)\n",
    "\n",
    "jaad_db = data_utils.JaadDatabase(jaad)\n",
    "jaad_db.run_database_generator()\n",
    "\n",
    "jaad_db.add_cropped_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3905422361.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/w3/mpbw0w2d5239lm7g55vdjzp80000gn/T/ipykernel_70423/3905422361.py\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    img_name_zero_padding = 5\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SkeletonPipeline:\n",
    "    def __init__(self, jaad_db, **opts):\n",
    "        self.jaad_db = jaad_db\n",
    "        self.jaad_obj = jaad_db.jaad_obj\n",
    "        self.opts = opts\n",
    "        \n",
    "        self._clips_paths = self.jaad_obj._clips_path\n",
    "        self._images_path = self.jaad_obj._images_path\n",
    "        self._jaad_path = self.jaad_obj._jaad_path\n",
    "        self._processed_dirpath = self.jaad_db.processed_dirpath\n",
    "        \n",
    "        # Load Config File\n",
    "        self.config_file = 'config.yaml'\n",
    "        self.config_path = Path.absolute(Path(self.config_file))\n",
    "        self.config = yaml.load(self.config_path.read_text(), Loader=yaml.SafeLoader)\n",
    "        self.root_path = Path.absolute(Path('.'))\n",
    "        \n",
    "        self.params = dict (\n",
    "            video_name_zero_padding = 4\n",
    "            img_name_zero_padding = 5\n",
    "            video_prefix = 'video_'\n",
    "            cropped_folder_name = 'cropped'\n",
    "            openpose_dir = None\n",
    "        )\n",
    "        assert all(k in self.params for k in self.opts.keys()), \"Wrong option(s).\"\n",
    "        self.params.update(self.opts)\n",
    "        self.params.update(self.config)\n",
    "        \n",
    "    assert self.params['openpose_dir'] is not None, \"Openpose directory not specified.\"\n",
    "    \n",
    "    def extract_frames(self, video_name, output_dir_path):\n",
    "        video_dirpath = self._clips_paths\n",
    "        video_path = str(video_dirpath / video_name) + \".mp4\"\n",
    "        frame_extract.video_to_frames(video_path=video_path, frames_dir=output_dir_path, overwrite=True, every=1, chunk_size=50)\n",
    "    \n",
    "    def _get_num_frames(self, video_name):\n",
    "        return self.db[video_name]['num_frames']\n",
    "    \n",
    "    def _run_crop_pipeline(self, video_name, pid):\n",
    "        cropped_path = Path(self._processed_dirpath) / video_name / self.params['cropped_folder_name'] / pid\n",
    "        \n",
    "        # for easier access\n",
    "        ped_annotations  = self.jaad_db.db[video_name]['ped_annotations']\n",
    "        frames = ped_annotations[pid]['frames']\n",
    "        cropped_boxes = ped_annotations[pid]['cropped_box']\n",
    "        \n",
    "        for frame in frames: \n",
    "            frame_ix = frames.index(frame)\n",
    "            print('Cropping frame {} of {}'.format(frame, pid), end='\\r', flush=True)\n",
    "            \n",
    "            frame_filename = str(frame).zfill(self.params['img_name_zero_padding']) + '.png'\n",
    "            frame_filepath = cropped_path / frame_filename\n",
    "            \n",
    "            img = cv2.imread(str(frame_filepath))\n",
    "            \n",
    "            [left, top, right, bottom] = cropped_boxes[frame_ix]\n",
    "            \n",
    "            cropped_img = img[top:bottom, left:right]\n",
    "            cv2.imwrite(str(frame_filepath), cropped_img)\n",
    "            \n",
    "        print('\\n')\n",
    "        return None\n",
    "    \n",
    "    def _run_extraction_pipeline(self, video_image_dir, video_name):    \n",
    "    # SECTION: Check if we already have the extracted frames or we need to extract them\n",
    "        # if image_dir doesnt exist, create it, extract frames\n",
    "        if not video_image_dir.exists:\n",
    "            print('Extracting frames for video {}'.format(video_name))\n",
    "            Path.mkdir(video_image_dir, exist_ok=True, parents=True)\n",
    "            self.extract_frames(video_name, video_image_dir)\n",
    "        else:\n",
    "            # if image_dir exists, check if we have the correct number of frames in it   \n",
    "            # get length of frames for video\n",
    "            frame_count = self._get_num_frames(video_name)\n",
    "            # get number of frames already in folder\n",
    "            frame_count_in_folder = len(list(Path(video_image_dir).rglob('*.png')))\n",
    "            if frame_count > frame_count_in_folder:\n",
    "                print('Frames for video {} are missing. Extracting frames.'.format(video_name))\n",
    "                shutil.rmtree(video_image_dir, ignore_errors=False, onerror=None)\n",
    "                Path.mkdir(video_image_dir, exist_ok=True, parents=True)\n",
    "                self.extract_frames(video_name, video_image_dir)\n",
    "            else:\n",
    "                print('Frames for video {} are already extracted.'.format(video_name))\n",
    "        return None\n",
    "    \n",
    "    def _build_openpose_command(self, flags, video_name, pid, cropped_image_dir):\n",
    "        full_command_list = list()\n",
    "        \n",
    "        # executable\n",
    "        bin_path_execute = \"./build/examples/openpose/openpose.bin\" # path to executable\n",
    "        full_command_list.append(bin_path_execute)\n",
    "        \n",
    "        # cropped image dir\n",
    "        image_args = [\"--image_dir\", cropped_image_dir]\n",
    "        full_command_list += image_args # add image_args to full_command_list\n",
    "        \n",
    "        # add flags\n",
    "        for flag, value in flags.items():\n",
    "            if value != None:\n",
    "                full_command_list += [\"--\" + flag, value]\n",
    "            else:\n",
    "                full_command_list += [\"--\" + flag]\n",
    "        return full_command_list\n",
    "        \n",
    "    def _run_inference_pipeline(self, flags, video_name, pid):\n",
    "        # TODO Finish this\n",
    "        cropped_image_dir = Path(self._processed_dirpath) / video_name / self.params['cropped_folder_name'] / pid\n",
    "        \n",
    "        built_in_flags = {\n",
    "                    \"write_json\": output_dir_path + \"/json/\" + video_name + \"/\" + track,\n",
    "                    \"write_images\": output_dir_path + \"/images/\" + video_name + \"/\" + track,\n",
    "                }  \n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _single_video_pipeline_constructor(self, video_name, **opts):\n",
    "        \n",
    "        params = {\n",
    "            \"cropping\": True,\n",
    "            \"keypoints\": True,\n",
    "            \"force\": True\n",
    "        }\n",
    "        assert all(k in self.params for k in self.opts.keys()), \"Wrong option(s).\"\n",
    "        self.params.update(self.opts)\n",
    "        \n",
    "        video_pipeline = {\n",
    "                'inf': {},\n",
    "                'crop': {},\n",
    "                'ext': False\n",
    "            }\n",
    "        \n",
    "        # set variable for easier access\n",
    "        ped_annotations_dict = self.jaad_db.db[video_name]['ped_annotations']\n",
    "        \n",
    "        for pid in ped_annotations_dict.keys():\n",
    "            \n",
    "            video_pipeline['inf'][pid] = False\n",
    "            video_pipeline['crop'][pid] = False\n",
    "            \n",
    "            if 'b' in pid: # only do this on pedestrians with annotations (string ending in b)\n",
    "                \n",
    "                # SECTION KEYPOINTS\n",
    "                if params['keypoints']: # are we supposed to run the keypoints pipeline?\n",
    "                    if (len(ped_annotations_dict[pid].get('skeleton_keypoints', [])) < 10) or (params['force']): # do we have less than 10 keypoints? or are we forced to run?\n",
    "                        video_pipeline['inf'][pid] = True\n",
    "                \n",
    "        \n",
    "        pid_to_infer = [k for k, v in video_pipeline['inf'].items() if v] # get list of pids that need to be inferred\n",
    "                \n",
    "        for pid in pid_to_infer:\n",
    "            # SECTION CROPPING\n",
    "            if params['cropping']: # are we supposed to run the cropping pipeline?\n",
    "                cropped_path = Path(self._processed_dirpath) / video_name / self.params['cropped_folder_name'] / pid\n",
    "                if not cropped_path.exists(): # are we missing the cropped images?\n",
    "                    Path.mkdir(cropped_path, parents=True, exist_ok=True)\n",
    "                    video_pipeline['crop'][pid] = True\n",
    "                else:\n",
    "                    num_crop_boxes = len(list(cropped_path.rglob('*.png')))\n",
    "                    if (num_crop_boxes < 10) or (params['force']): # do we have less than 10 cropped boxes? or are we forced to run?\n",
    "                        video_pipeline['crop'][pid] = True\n",
    "\n",
    "            if video_pipeline['crop'][pid]:\n",
    "                video_pipeline['ext'] = True\n",
    "        \n",
    "        return video_pipeline\n",
    "        \n",
    "    def prepare_images(self, run_cropping=True, run_keypoints=True, force=False):\n",
    "        \n",
    "        params = {\n",
    "            \"cropping\": run_cropping,\n",
    "            \"keypoints\": run_keypoints,\n",
    "            \"force\": force\n",
    "        }\n",
    "        \n",
    "        print('Preparing images with the following parameters:')\n",
    "        for item in params.items():\n",
    "            print (item)\n",
    "        \n",
    "        # if we passed skip_cropping as false, we must have the cropped bounding boxes \n",
    "        if run_cropping:\n",
    "            assert self.jaad_db.cropped_run == True, \"Can't crop images, cropped bounding boxes have not been extracted. Please run `add_cropped_box` first.\"\n",
    "\n",
    "        counter = 0\n",
    "        time_tracker = 0\n",
    "        for video_name in self.jaad_db.db.keys():\n",
    "            t0 = time.time() # start timer\n",
    "            # set required paths\n",
    "            video_image_dir = Path(self._images_path) / video_name\n",
    "\n",
    "            video_pipeline = self._single_video_pipeline_constructor(video_name, **params)\n",
    "            \n",
    "            crop_pid_list = [k for k, v in video_pipeline['crop'].items() if v]\n",
    "            infer_pid_list = [k for k, v in video_pipeline['inf'].items() if v]\n",
    "            \n",
    "            if video_pipeline['ext']:\n",
    "                self._run_extraction_pipeline(video_image_dir, video_name)\n",
    "            else:\n",
    "                print('Extraction for video {} not required.'.format(video_name))\n",
    "            for pid in crop_pid_list:\n",
    "                self._run_crop_pipeline()(video_name, pid)\n",
    "            for pid in infer_pid_list:\n",
    "                os.chdir(self._openpose_dirpath)\n",
    "                self._run_inference_pipeline(video_name, pid)\n",
    "                os.chdir(self._root_dirpath)\n",
    "            counter += 1\n",
    "            time_diff = time.time() - t0\n",
    "            time_tracker += time_diff\n",
    "            mean_time = time_tracker / counter\n",
    "            video_queue_length = len(self.jaad_db.db.keys())\n",
    "            print(\"\\n\")\n",
    "            print(\"Elapsed time: \", time_diff, \" seconds\")\n",
    "            print(\"Time remaining: \", mean_time * video_queue_length - counter), \" seconds\")\n",
    "            print(\"Processed \", counter, \" out of \", video_queue_length, \" videos\")\n",
    "            print(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = jaad_db.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'video_0001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database saved to data/processed/jaad_database.pkl\n"
     ]
    }
   ],
   "source": [
    "jaad_db.add_cropped_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data/processed/keypoints/video_0002/0_2_5b",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w3/mpbw0w2d5239lm7g55vdjzp80000gn/T/ipykernel_70423/2276578486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjaad_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/local-projects/pedestrians/src/data_utils.py\u001b[0m in \u001b[0;36mappend_keypoints\u001b[0;34m(self, keypoint_dir, **opts)\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_keypoint_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_keypoint_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mprocessed_keypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: data/processed/keypoints/video_0002/0_2_5b"
     ]
    }
   ],
   "source": [
    "jaad_db.append_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = jaad_db.db\n",
    "db1 = db['video_0001']['ped_annotations']\n",
    "db2 = db['video_0002']['ped_annotations']['0_2_5b']['cropped_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1488, 549, 1640, 1046]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_pipeline = {}\n",
    "video_pipeline['inf'] = {}\n",
    "video_pipeline['inf']['asd'] = True\n",
    "video_pipeline['inf']['dsa'] = False\n",
    "video_pipeline['inf']['vmlks'] = False\n",
    "video_pipeline['inf']['vmnksc'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n",
      "vmnksc\n"
     ]
    }
   ],
   "source": [
    "for k, v in video_pipeline['inf'].items():\n",
    "    if v:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asd', 'vmnksc']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in video_pipeline['inf'].items() if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Path.absolute(p) / 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openpose_dir': '/Users/seba/local-projects/openpose'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml.load(p2.read_text(), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/seba/local-projects/pedestrians/config.yaml')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.absolute(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1983208fc3b676051846d4560864203f9ebdf64099edd8febcc8dd3d7f3fa9dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml-base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
