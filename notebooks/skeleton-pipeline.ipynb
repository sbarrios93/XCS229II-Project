{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding of leading zeros on video names\n",
    "VIDEO_NAME_ZERO_PADDING = 4\n",
    "\n",
    "# padding of leading zeros on static images names\n",
    "IMG_NAME_ZERO_PADDING = 5\n",
    "\n",
    "\n",
    "# Static Paths\n",
    "# notebook is inside notebook folder (not in root)\n",
    "ROOT_DIR = Path().resolve().parent\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "ANNOTATIONS_DIR = DATA_DIR / 'annotations'\n",
    "\n",
    "# static image dir\n",
    "IMG_DIR = DATA_DIR / 'images'\n",
    "\n",
    "# OPENPOSE_PROCESSING_DIR\n",
    "OP_PROCESSING_DIR = ROOT_DIR / 'openpose_processing'\n",
    "# Make dir if it doesnt exist, don't complain if it does\n",
    "OP_PROCESSING_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# BBOX_METADATA FILENAME\n",
    "BBOX_METADATA_FILENAME = 'bbox_metadata.json'\n",
    "\n",
    "# CROPS_METADATA FILENAME\n",
    "CROPS_METADATA_FILENAME = 'crops_metadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video for testing, we dont want to use all of them, just one\n",
    "VIDEO_PREFIX = \"video_\"\n",
    "VIDEO_IX = [i+1 for i in range(346)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w3/mpbw0w2d5239lm7g55vdjzp80000gn/T/ipykernel_11440/4260669464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# get list of files that appear in queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mqueue_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxml_files\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mxml_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create list of videos to process using JAAD file formatting video_000\\d.mp4\n",
    "queue = [VIDEO_PREFIX + str(ix).zfill(VIDEO_NAME_ZERO_PADDING) for ix in VIDEO_IX]\n",
    "\n",
    "# get list of all videos in data folder\n",
    "xml_files = glob.glob(str(ANNOTATIONS_DIR / '*.xml'))\n",
    "# get list of files that appear in queue\n",
    "queue_path = {xml.stem: xml for xml in xml_files if xml.stem in queue}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify obtention of bounding box coordinates\n",
    "Will save in openpose_processing folder file: `bbox_metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tracks(filepath):\n",
    "    # here will go the data that will output to json\n",
    "    tracks_dict = dict()\n",
    "    \n",
    "    # run xml parser\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # find all tracks in the xml file\n",
    "    tracks = root.findall('track')\n",
    "    \n",
    "    # for each track, find all the bounding boxes and their metadata \"items\", we also need the id which\n",
    "    # is the id of each pedestrian\n",
    "    for i, track in enumerate(tracks):\n",
    "        # the id is inside the box, so we need to retrieve it later, we start with id=None\n",
    "        # to check later if id = None, else set it on the first iteration\n",
    "        id = None\n",
    "        boxes = track.findall('.//box')\n",
    "        for box in boxes:\n",
    "            if id is None:\n",
    "                id = box.findall(\".//attribute/[@name='id']\")[0].text\n",
    "                tracks_dict[id] = {}\n",
    "            occlusion = box.findall(\".//attribute/[@name='occlusion']\")[0].text\n",
    "            items = dict(box.items())\n",
    "            items['occlusion'] = occlusion\n",
    "            frame = items['frame']\n",
    "            tracks_dict[id][frame] = items\n",
    "    return tracks_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bbox_metadata(path, video_name, name, data):\n",
    "    \n",
    "    path_dir = path / video_name\n",
    "    filepath_dir = path_dir / name\n",
    "    \n",
    "    # make dir if it doesnt exist, don't complain if it does\n",
    "    Path.mkdir(path_dir, exist_ok=True, parents=True)\n",
    "    \n",
    "    with open(filepath_dir, 'w') as f:\n",
    "        f.write(json.dumps(data, indent=4))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_name, filepath in queue_path.items():\n",
    "    data = parse_tracks(filepath)\n",
    "    save_bbox_metadata(path=OP_PROCESSING_DIR, video_name=video_name, name=BBOX_METADATA_FILENAME, data=data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../openpose_path.env\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP_EXECUTABLE = os.environ['OP_EXECUTABLE']\n",
    "\n",
    "\n",
    "# folder name for the cropped images\n",
    "CROPPED_DIR = 'cropped' \n",
    "\n",
    "# how much padding to leave around bounding box when cropping images\n",
    "BORDER_PADDING = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for video_name in queue_path.keys():\n",
    "    # set required paths\n",
    "    image_dir = IMG_DIR / video_name\n",
    "    metadata_filepath = OP_PROCESSING_DIR / video_name / BBOX_METADATA_FILENAME\n",
    "    \n",
    "    crops_metadata_filepath = OP_PROCESSING_DIR / video_name / CROPS_METADATA_FILENAME\n",
    "    crops_metadata_dict = dict()\n",
    "    \n",
    "    with open(metadata_filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    tracks = list(data.keys())\n",
    "    \n",
    "    for track in tracks:\n",
    "        crops_metadata_dict[track] = dict()\n",
    "        # DIR to save cropped images\n",
    "        cropped_im_dir = OP_PROCESSING_DIR / video_name / CROPPED_DIR / track\n",
    "        Path.mkdir(cropped_im_dir, exist_ok=True, parents=True)\n",
    "        \n",
    "        frames = list(data[track].keys())\n",
    "        \n",
    "        \n",
    "        # for each frame theres an image, let's get the image full path for the frame and crop it using the bbox, save it\n",
    "        for frame in frames:\n",
    "            frame_filename = str(frame).zfill(IMG_NAME_ZERO_PADDING) + '.png'\n",
    "            frame_filepath = image_dir / frame_filename\n",
    "            \n",
    "            frame_data = data[track][frame]\n",
    "            \n",
    "            img = cv2.imread(str(frame_filepath))\n",
    "            \n",
    "            (left, top, right, bottom) = (int(float(frame_data['xtl'])), int(float(frame_data['ytl'])), int(float(frame_data['xbr'])), int(float(frame_data['ybr'])))\n",
    "            \n",
    "            left = max(0, left - int(BORDER_PADDING * (right - left)))\n",
    "            right = min(img.shape[1], right + int(BORDER_PADDING * (right - left)))\n",
    "            top = max(0, top - int(BORDER_PADDING * (bottom - top)))\n",
    "            bottom = min(img.shape[0], bottom + int(BORDER_PADDING * (bottom - top)))\n",
    "            \n",
    "            crops_metadata_dict[track][frame] = {'left': left, 'top': top, 'right': right, 'bottom': bottom}\n",
    "            \n",
    "            # crop image\n",
    "            cropped_img = img[top:bottom, left:right]\n",
    "            (height, width, filters) = cropped_img.shape\n",
    "            \n",
    "            cv2.imwrite(str(cropped_im_dir / f'{frame}.png'), cropped_img)\n",
    "    \n",
    "    with open(crops_metadata_filepath, 'w') as f:\n",
    "        json.dump(crops_metadata_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1983208fc3b676051846d4560864203f9ebdf64099edd8febcc8dd3d7f3fa9dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml-base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
